{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examen: Aprendizaje Automatico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JFME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizacion general del proyecto (version simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. main.py : funcionalidad principal\n",
    "2. experiments.py : registro de experimentos\n",
    "3. functions.py : funciones de proyecto\n",
    "4. otros archivos complementarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functions as fn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('files/train.csv')\n",
    "data_test = pd.read_csv('files/test.csv')\n",
    "ids_train = data_train['id']\n",
    "data_train.drop('id', inplace=True, axis=1)\n",
    "ids_test = data_test['id']\n",
    "data_test.drop('id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul']\n",
    "\n",
    "# ------------------------------------------------------------------------------------- D1: DATA SCALING -- #\n",
    "mu_train, std_train = data_train[feats].mean(axis=0), data_train[feats].std(axis=0)\n",
    "z_train = (data_train[feats] - mu_train)/std_train\n",
    "data_train[feats] = z_train\n",
    "\n",
    "mu_test, std_test = data_test[feats].mean(axis=0), data_test[feats].std(axis=0)\n",
    "z_test = (data_test[feats] - mu_test)/std_test\n",
    "data_test[feats] = z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Dummy variables with color\n",
    "data_train = pd.concat([data_train, pd.get_dummies(data_train['color'], prefix = 'color')], axis=1)\n",
    "data_train = data_train.drop('color', 1)\n",
    "data_test = pd.concat([data_test, pd.get_dummies(data_test['color'], prefix = 'color')], axis=1)\n",
    "data_test = data_test.drop('color', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- One-hot encode target variable\n",
    "data_train['type'] = fn.variable_onehot(p_data=data_train['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Add Bias \n",
    "data_train['bias'] = 1\n",
    "data_columns = list(data_train.columns)\n",
    "data_columns.remove('bias')\n",
    "data_train = data_train[['bias'] + data_columns]\n",
    "\n",
    "data_test['bias'] = 1\n",
    "data_columns = list(data_test.columns)\n",
    "data_columns.remove('bias')\n",
    "data_test = data_test[['bias'] + data_columns]\n",
    "\n",
    "# -- Convert to np.array\n",
    "train_data_ovr = fn.data_ovr(p_df=data_train, p_target='type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training multiple models using One Vs Rest Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mejora encontrada para:  data_0\n",
      "mejora encontrada para:  data_1\n",
      "mejora encontrada para:  data_2\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------- learning based in ovr -- #  \n",
    "models_ovr = fn.ovr_learning(p_data_ovr=train_data_ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda': 0.25, 'alpha': 0.1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model inf\n",
    "models_ovr['model_0']['train']['cost']\n",
    "models_ovr['model_0']['val']['cost']\n",
    "models_ovr['model_0']['fitted_cost']\n",
    "models_ovr['model_0']['weights']\n",
    "models_ovr['model_0']['params']\n",
    "\n",
    "models_ovr['model_0']['train']['cost']\n",
    "models_ovr['model_0']['val']['cost']\n",
    "models_ovr['model_0']['fitted_cost']\n",
    "models_ovr['model_0']['weights']\n",
    "models_ovr['model_0']['params']\n",
    "\n",
    "models_ovr['model_0']['train']['cost']\n",
    "models_ovr['model_0']['val']['cost']\n",
    "models_ovr['model_0']['fitted_cost']\n",
    "models_ovr['model_0']['weights']\n",
    "models_ovr['model_0']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- convert to np.array\n",
    "test_data_ovr = np.array(data_test)\n",
    "\n",
    "# -- prediction based in ovr\n",
    "# vote weighting (ocurrences in train data)\n",
    "oc = data_train['type'].value_counts()\n",
    "vw = [np.round(oc[0]/oc.sum(), 4),\n",
    "      np.round(oc[1]/oc.sum(), 4),\n",
    "      np.round(oc[2]/oc.sum(), 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    227\n",
       "2    183\n",
       "1    119\n",
       "Name: decision, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result\n",
    "result = fn.ovr_predict(p_data_ovr=test_data_ovr, p_models_ovr=models_ovr, p_vote_w=vw)\n",
    "\n",
    "# probabilistic results\n",
    "result.head()\n",
    "\n",
    "# check for balance of classes before summit results\n",
    "result['decision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define experiment tag\n",
    "experiment = 'submission_v23'\n",
    "\n",
    "# -------------------------------------------------------------------------------------- SUBMISSION FILE -- #\n",
    "submission = pd.DataFrame({'id': ids_test, 'type': result['decision']})\n",
    "type_dict_sub = {0: 'Ghoul', 1: 'Goblin', 2: 'Ghost'}\n",
    "submission['type'] = submission['type'].map(type_dict_sub).astype(object)\n",
    "submission.to_csv('files/submissions/' + experiment + '.csv', index=False)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------ PICKLE RICK -- #\n",
    "pickle_rick = 'files/submissions/' + experiment + '.dat'\n",
    "with open(pickle_rick, \"wb\") as f:\n",
    "    pickle.dump(models_ovr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento mas alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- [v223]\n",
    "# 221 - inv-weighted hypercost\n",
    "\n",
    "# scalling = standarizacion\n",
    "# dummies = color\n",
    "# bias = si\n",
    "# epochs = 10000\n",
    "# sample split = 0.20\n",
    "# tolerance = 1e-4\n",
    "# hyper_m0 = {'lambda': 1.1, 'alpha': 0.01}\n",
    "# hyper_m1 = {'lambda': 1.1, 'alpha': 0.01}\n",
    "# hyper_m2 = {'lambda': 1.1, 'alpha': 0.01}\n",
    "# funcion para eleccion de hyper = train*0.2 + val*0.8\n",
    "\n",
    "# peso para voto = [0.3477, 0.3369, 0.3154]\n",
    "# 0    219\n",
    "# 2    199\n",
    "# 1    111\n",
    "# acc_test = 0.7710\n",
    "# archivo = submission_v223.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " # read the file\n",
    "p_data_file = 'files/submissions/v223/submission_v223.dat'\n",
    "with open(p_data_file, 'rb') as handle:\n",
    "    loaded_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93651695,  0.93096208, -0.05026663,  1.26367671,  1.11980552,\n",
       "        -0.01226787, -0.46240712, -0.60463049, -0.59249564, -0.5292599 ,\n",
       "        -0.12712157]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['model_0']['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4493858 , -0.04434608, -0.54610138,  0.08303783,  0.00189016,\n",
       "         0.01766091, -0.00620579,  0.04717678, -0.05580948, -0.03131267,\n",
       "        -0.19821383]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['model_1']['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69380248, -0.53084577,  0.80817991, -0.88950331, -0.82819126,\n",
       "        -0.00586256,  0.08341573,  0.00269831, -0.15032823,  0.02644557,\n",
       "        -0.21345502]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['model_2']['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit169fb845afdb4f1cbcbb34e10de7bef4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
